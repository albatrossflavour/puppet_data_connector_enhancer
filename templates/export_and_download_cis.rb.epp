<%- | String $scm_host,
      Sensitive[String] $auth,
      Integer $export_retention,
      Integer $poll_interval,
      Integer $max_wait_time,
      String $scm_dir,
      String $scm_log_file,
| -%>
#!/opt/puppetlabs/puppet/bin/ruby
#
# Name: export_and_download_cis.rb
# Purpose: To create, poll for completion, and download CIS summary report from SCM host
#

require 'net/http'
require 'openssl'
require 'uri'
require 'json'
require 'time'
require 'fileutils'
require 'logger'

# Set up logging
log = Logger.new('<%=$scm_log_file %>')
log.level = Logger::INFO

#################################################################################################################################

def create_export(host, token, log)
  # Generate a new "compliance_status_summary" report
  log.info('Creating new compliance_status_summary export')

  create_export_api = '/api/public/v1/export-job'
  report_title = 'Summary_Report_API'
  url = URI(host + create_export_api)

  http = Net::HTTP.new(url.host, url.port)
  http.use_ssl = true
  http.verify_mode = OpenSSL::SSL::VERIFY_NONE
  request = Net::HTTP::Post.new(url)
  request['Content-Type'] = 'application/json'
  request['Accept'] = 'application/json'
  request['Authorization'] = token
  request.body = JSON.dump({ 'type': 'compliance_status_summary', 'description': 'API Generated', 'name': report_title })
  response = http.request(request)

  if response.code == '201'
    result = JSON.parse(response.body)
    log.info("Export job created successfully with ID: #{result['id']}")
    return result
  else
    log.error("HTTP Error from create_export: #{response.code} - #{response.body}")
    abort "HTTP Error from <create_export>: #{response.code}"
  end
end

#################################################################################################################################

def create_export_with_retry(host, token, log, max_retries: 3)
  # Create export with exponential backoff retry logic
  attempt = 0
  base_delay = 60

  loop do
    attempt += 1
    begin
      return create_export(host, token, log)
    rescue StandardError => e
      if attempt >= max_retries
        log.fatal("Failed to create export after #{max_retries} attempts: #{e.message}")
        raise
      end

      delay = base_delay * (2 ** (attempt - 1))
      log.warn("Export creation attempt #{attempt} failed: #{e.message}. Retrying in #{delay}s...")
      sleep delay
    end
  end
end

#################################################################################################################################

def list_exports(host, token, log)
  # API reports query
  list_api = '/api/public/v1/exports'
  url = URI(host + list_api)

  http = Net::HTTP.new(url.host, url.port)
  http.use_ssl = true
  http.verify_mode = OpenSSL::SSL::VERIFY_NONE

  request = Net::HTTP::Get.new(url)
  request['Accept'] = 'application/json'
  request['Authorization'] = token

  response = http.request(request)

  if response.code == '200'
    return JSON.parse(response.body)
  else
    log.error("HTTP Error from list_exports: #{response.code}")
    abort "HTTP Error from <list_exports>: #{response.code}"
  end
end

#################################################################################################################################

def poll_for_export(export_id, host, token, poll_interval, max_wait, log)
  # Poll for export completion
  log.info("Polling for export ID #{export_id} completion (max wait: #{max_wait}s, interval: #{poll_interval}s)")

  start_time = Time.now
  attempts = 0

  loop do
    attempts += 1
    elapsed = Time.now - start_time

    if elapsed > max_wait
      log.error("Export polling timeout after #{elapsed.round}s (#{attempts} attempts)")
      abort "Timeout waiting for export #{export_id} to complete after #{max_wait}s"
    end

    exports = list_exports(host, token, log)
    export = exports.find { |e| e['id'] == export_id }

    if export
      log.info("Export #{export_id} found after #{elapsed.round}s (#{attempts} attempts)")
      return export
    end

    log.debug("Export #{export_id} not ready, waiting #{poll_interval}s (attempt #{attempts}, elapsed #{elapsed.round}s)")
    sleep poll_interval
  end
end

#################################################################################################################################

def download_export(report, host, token, log)
  # Download the compliance report
  log.info("Downloading export ID: #{report['id']}")

  r_id = report['id'].to_s
  file_name = 'compliance_summary_report.zip'
  download_api = '/api/public/v1/export/' + r_id + '/file'

  url = URI(host + download_api)
  http = Net::HTTP.new(url.host, url.port)
  http.use_ssl = true
  http.verify_mode = OpenSSL::SSL::VERIFY_NONE
  request = Net::HTTP::Get.new(url)
  request['Authorization'] = token
  response = http.request(request)

  if response.code == '200'
    File.open(file_name, 'w', 0600) do |file|
      file.write(response.body)
    end
    log.info("Export downloaded successfully to #{file_name}")
  else
    log.error("HTTP Error from download_export: #{response.code}")
    abort "HTTP Error from <download_export>: #{response.code}"
  end
end

#################################################################################################################################

def process_export(scm_dir, t_stamp, log)
  # The export is a zip file, unzip, uncompress
  log.info('Processing export file')

  zip_file = 'compliance_summary_report.zip'
  score_data_dir = "#{scm_dir}/score_data"

  if File.exist?(zip_file)
    tmp_dir = 'Summary_Report_' + t_stamp.strftime('%d_%m_%Y_%H_%M_%S')
    Dir.mkdir(tmp_dir)
    FileUtils.mv(zip_file, tmp_dir)
    Dir.chdir(tmp_dir)
    # unzip the download and uncompress the gz files
    # Requires double quotes despite the linting suggestions !
    # rubocop:disable Style/StringLiterals
    if system("unzip #{zip_file} > /dev/null")
      system("find . -name \"*.gz\" -exec gzip -d {} \\; > /dev/null")
      # rubocop:enable Style/StringLiterals
      if File.exist?("#{score_data_dir}/#{tmp_dir}/Summary_Report_API.csv")
        # csv confirmed start clean-up
        File.delete(zip_file)
        FileUtils.mv('Summary_Report_API.csv', score_data_dir)
        # Set permissions so pe-puppet user can read the CSV during catalog compilation
        File.chmod(0644, "#{score_data_dir}/Summary_Report_API.csv")
        Dir.chdir(score_data_dir)
        Dir.delete(tmp_dir)
        log.info('Export processed successfully')
      else
        log.error('CSV file not detected after extraction')
        puts 'Something went wrong, csv file not detected'
      end
    else
      log.error("Unzip of #{zip_file} failed")
      puts "Unzip of #{zip_file} failed"
    end
  else
    log.warn('No zip file present, nothing to do')
    puts 'No zip file present, nothing to do'
  end
end

#################################################################################################################################

def clean_up(list, host, token, retain, log)
  # Only retain the specified number of reports generated by this module
  log.info("Cleaning up old exports (retention: #{retain})")

  api_reports = list.filter {|t| t['type'] == 'compliance_status_summary' && t['description'] == 'API Generated' }
  sorted_list = api_reports.sort_by {|time| time[:created_at]}

  if sorted_list.count > retain
    delete_count = sorted_list.count - (retain + 1)
    log.info("Deleting #{delete_count + 1} old exports")
    sorted_list[0..delete_count].each do | item |
      delete_api = '/api/public/v1/export/' + "#{item['id']}"
      url = URI(host + delete_api)
      http = Net::HTTP.new(url.host, url.port)
      http.use_ssl = true
      http.verify_mode = OpenSSL::SSL::VERIFY_NONE
      request = Net::HTTP::Delete.new(url)
      request["Authorization"] = token
      response = http.request(request)

      if response.code == '204'
        log.info("Deleted export ID: #{item['id']}")
      else
        log.error("HTTP Error from clean_up: #{response.code} for export ID #{item['id']}")
        abort "HTTP Error from <clean_up>: #{response.code}"
      end
    end
  else
    log.info("No cleanup needed (#{sorted_list.count} exports, retention: #{retain})")
  end
end

#################################################################################################################################

def write_status_file(scm_dir, status_data, log)
  # Write status file for Prometheus monitoring
  status_file = "#{scm_dir}/scm_export_status.json"

  begin
    File.open(status_file, 'w', 0644) do |file|
      file.write(JSON.pretty_generate(status_data))
    end
    log.debug("Wrote status file: #{status_file}")
  rescue StandardError => e
    log.error("Failed to write status file: #{e.message}")
  end
end

#################################################################################################################################

def count_csv_nodes(csv_path, log)
  # Count number of nodes in CSV file
  return 0 unless File.exist?(csv_path)

  lines = File.readlines(csv_path)
  # Subtract 1 for header row, count non-empty lines
  node_count = lines.count { |line| !line.strip.empty? } - 1
  log.debug("Counted #{node_count} nodes in CSV")
  node_count
rescue StandardError => e
  log.warn("Error counting nodes in CSV: #{e.message}")
  0
end

#################################################################################################################################

begin
  # Declare variables
  scm_host = '<%=$scm_host %>'
  auth = 'Bearer <%=$auth %>'
  current_time = Time.now.utc.getlocal
  scm_dir = '<%=$scm_dir %>'
  score_data_dir = '<%=$scm_dir %>/score_data'
  csv_path = "#{score_data_dir}/Summary_Report_API.csv"
  poll_interval = <%=$poll_interval %>
  max_wait_time = <%=$max_wait_time %>
  export_retention = <%=$export_retention %>

  start_time = Time.now.to_f

  log.info('=== Starting CIS export and download process ===')

  # Create new export with retry logic
  new_export = create_export_with_retry(scm_host, auth, log)
  export_id = new_export['id']

  # Poll for completion
  completed_export = poll_for_export(export_id, scm_host, auth, poll_interval, max_wait_time, log)

  # Download and process
  Dir.chdir(score_data_dir)
  download_export(completed_export, scm_host, auth, log)
  process_export(scm_dir, current_time, log)

  # Clean up old exports
  all_exports = list_exports(scm_host, auth, log)
  clean_up(all_exports, scm_host, auth, export_retention, log)

  log.info('=== CIS export and download process completed successfully ===')

  # Write success status
  duration = Time.now.to_f - start_time
  nodes_exported = count_csv_nodes(csv_path, log)

  write_status_file(scm_dir, {
    last_run_timestamp: Time.now.to_i,
    last_success_timestamp: Time.now.to_i,
    status: 'success',
    duration_seconds: duration.round(2),
    export_id: export_id,
    nodes_exported: nodes_exported,
    error_message: nil
  }, log)

rescue StandardError => e
  log.fatal("Fatal error: #{e.class} - #{e.message}")
  log.fatal(e.backtrace.join("\n"))

  # Write failure status
  duration = Time.now.to_f - start_time
  write_status_file(scm_dir, {
    last_run_timestamp: Time.now.to_i,
    last_success_timestamp: nil,
    status: 'failed',
    duration_seconds: duration.round(2),
    export_id: defined?(export_id) ? export_id : nil,
    nodes_exported: 0,
    error_message: "#{e.class}: #{e.message}"
  }, log)

  abort "Fatal error: #{e.message}"
end
